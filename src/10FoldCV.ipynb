{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GerardoFesta/DLforJITDefectPrediction/blob/main/src/10FoldCV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmZSXbTkMPAN"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe = pd.read_csv(\"data_scaled.csv\")\n",
        "dataset = dataframe.values\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,2:26].astype(float)\n",
        "Y = dataset[:,1]"
      ],
      "metadata": {
        "id": "W3hUBfqiOpzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X))\n",
        "print(len(Y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8gp8LKZ00td",
        "outputId": "3dfe3f69-c958-4336-cd1c-b744ce73e8ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "193800\n",
            "193800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "encoded_Y = encoder.transform(Y)"
      ],
      "metadata": {
        "id": "8SE2W5lKPhDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.backend  import set_session,clear_session,get_session\n",
        "import gc\n",
        "\n",
        "# funzione per liberare spazio ad ogni iterazione della cross-validation\n",
        "def reset_keras():\n",
        "    sess = get_session()\n",
        "    clear_session()\n",
        "    sess.close()\n",
        "    sess = get_session()\n",
        "\n",
        "    try:\n",
        "        del model \n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    print(\"Reset Keras \",gc.collect()) \n",
        "\n",
        "    \n",
        "    config = tf.compat.v1.ConfigProto()\n",
        "    config.gpu_options.per_process_gpu_memory_fraction = 1\n",
        "    config.gpu_options.visible_device_list = \"0\"\n",
        "    set_session(tf.compat.v1.Session(config=config))"
      ],
      "metadata": {
        "id": "TS2dIIXvWvZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_model(grid):\n",
        "\t# create model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(24, input_shape=(24,), activation='linear',kernel_regularizer=tf.keras.regularizers.l2(grid[\"decay\"]),\n",
        "   bias_regularizer=tf.keras.regularizers.l2(grid[\"decay\"])))\n",
        "  for x in range(grid[\"hidden_size\"]):\n",
        "    model.add(Dense(13, activation='tanh',kernel_regularizer=tf.keras.regularizers.l2(grid[\"decay\"])))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  # optimizer\n",
        "  opt = SGD(\n",
        "    learning_rate=grid[\"lr\"], momentum=grid[\"momentum\"]\n",
        "  )\n",
        "\t# Compile model\n",
        "  model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "tUWYCB3qPozZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv  \n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
        "\n",
        "header = [ 'hidden_size', 'lr', \"momentum\", \"decay\", \"hasEarlyStopped\", \"10FoldCV-Loss\", \"10FoldCV-Acc\"]\n",
        "\n",
        "\n",
        "with open('result.csv', 'w') as f:\n",
        "    writer = csv.writer(f)\n",
        "    # write the header\n",
        "    writer.writerow(header)\n",
        "\n"
      ],
      "metadata": {
        "id": "OUgeWQpuVHcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import ParameterGrid\n",
        "# setto i valori dei parametri che voglio testare e creo tutte le possibili combinazioni\n",
        "param_grid = {'hidden_size': [1, 2, 3],'lr': [0.01, 0.001, 0.0001], \"momentum\":[0.7, 0.8, 0.9], \"decay\":[0.1, 0.3, 0.5]}\n",
        "expanded_grid = ParameterGrid(param_grid)\n",
        "\n",
        "batch_size=1024"
      ],
      "metadata": {
        "id": "Cn1M7Zy9QGIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "res ={\"hidden_size\":[], \"lr\":[], \"momentum\":[], \"decay\":[], \"EarlyStopped\":[], \"10FoldCV-Loss\":[], \"10FoldCV-Acc\":[]}\n",
        "\n",
        "for i in range(len(expanded_grid)):\n",
        "        print(expanded_grid[i])\n",
        "        fold_no=1\n",
        "        loss_per_fold=[]\n",
        "        acc_per_fold = []\n",
        "        for train, test in skf.split(X, encoded_Y):\n",
        "            model = create_model(expanded_grid[i])\n",
        "\n",
        "            \n",
        "            # Generate a print\n",
        "            print('------------------------------------------------------------------------')\n",
        "            print(f'Training for fold {fold_no} ...')\n",
        "            #Create the callback for early stopping monitor. If the loss doesn't improve for more than 4 iterations, it stops the process\n",
        "            callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=6, verbose = 1)\n",
        "            # Fit data to model\n",
        "            history = model.fit(X[train], encoded_Y[train],\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=150,\n",
        "                      verbose=1,\n",
        "                      steps_per_epoch=20,\n",
        "                      callbacks = [callback])\n",
        "            \n",
        "\n",
        "            # Generate generalization metrics\n",
        "            scores,acc = model.evaluate(X[test], encoded_Y[test], verbose=0)\n",
        "            #print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "            loss_per_fold.append(scores)\n",
        "            acc_per_fold.append(acc)\n",
        "            # Increase fold number\n",
        "            fold_no = fold_no + 1\n",
        "            #reset_keras()\n",
        "       \n",
        "        res[\"hidden_size\"].append(expanded_grid[i][\"hidden_size\"])\n",
        "        res[\"lr\"].append(expanded_grid[i][\"lr\"])\n",
        "        res[\"momentum\"].append(expanded_grid[i][\"momentum\"])\n",
        "        res[\"decay\"].append(expanded_grid[i][\"decay\"])\n",
        "  \n",
        "        res[\"EarlyStopped\"].append(len(history.history['loss']))\n",
        "        res[\"10FoldCV-Loss\"].append(round(sum(loss_per_fold)/10,3))\n",
        "        res[\"10FoldCV-Acc\"].append(round(sum(acc_per_fold)/10,3))\n",
        "        with open('result.csv', 'a') as f:\n",
        "                writer = csv.writer(f)\n",
        "                writer.writerow([res[\"hidden_size\"][i],res[\"lr\"][i],res[\"momentum\"][i],res[\"decay\"][i],res[\"EarlyStopped\"][i],res[\"10FoldCV-Loss\"][i],res[\"10FoldCV-Acc\"][i]])\n",
        "                print (i+1, \"/\", len(expanded_grid))\n"
      ],
      "metadata": {
        "id": "ZahQttkCQXkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('result.csv', 'a') as f:\n",
        "                writer = csv.writer(f)\n",
        "                writer.writerow([res[\"hidden_size\"][0],res[\"lr\"][0],res[\"momentum\"][0],res[\"decay\"][0],res[\"10FoldCV-Loss\"][0]])\n",
        "                print (i+1, \"/\", len(expanded_grid))\n",
        "\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVFFLpWyypgI",
        "outputId": "46d52b87-e64d-4869-b46a-452e953eec91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "81 / 81\n"
          ]
        }
      ]
    }
  ]
}